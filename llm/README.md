### README.md - LLM 

# Project Setup üõ†Ô∏è

### Step 1: Create the Conda Environment 'eon-llm'
First, ensure you have Conda installed (and 'Libmamba' enabled as resolver - much faster). Then run the following commands:

```sh
conda env create -f environment.yml
```

### Step 2: Activate the Environment
Activate the newly created environment:

```sh
conda activate eon-llm
```

## Step 3: Install (Potentially Missing) Packages with pip
With the `eon-llm` environment activated, install the required packages using the `requirements.txt` file provided:

```sh
pip install -r requirements.txt
```

### Step 4: Test if Packages Have Been Installed Properly
Run model predictions (`-p`) or (re-)run evaluation metrics (`-e`) for testing, for instance:

```sh
python scripts/run.py tuned -p
python scripts/run.py tuned -e --all
```

# Project Structure üóÇÔ∏è

This directory covers all LLM-related research directories and files, including:

**data:**
- The data (GermanQuAD and SQuAD) as provided by E.ON and used for fine-tuning (`train.json`) and prediction (`test/dev.json`).

**eval_results:**
- The summarized evaluation results for the defined metrics (e.g., BLEU, ROUGE, F1, exact match, ...) in 'metrics'.

**metrics:**
- The defined metrics to evaluate model results.

**model_results:**
- The predictions as generated by the different tested models.

**scripts:**
- The scripts to execute model fine-tuning (`fine-tune.py`), run predictions (`run.py` with commands `base.py` for pre-trained models and `tuned.py` for fine-tuned models), and utility functions (`utils.py`).

**level-0.ipynb:**
- This Jupyter notebook is used for experimentation and to generate visualizations for model & evaluation results.

--------------------

**IMPORTANT:**
- Results (evaluation or models) are always separated by model types (i.e., base, Gbase, tuned, Gtuned).

Please update the content in case of changes. 